{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import texttable as tt\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Activation, Input, Dropout, Add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imgs(data_dir):\n",
    "    animal_to_imgs = {}\n",
    "    for animal_name in os.listdir(data_dir):\n",
    "        animal_to_imgs[animal_name] = []\n",
    "        animal_dir = data_dir + \"/\" + animal_name + \"/\"\n",
    "        for img_name in os.listdir(animal_dir):\n",
    "            img = plt.imread(animal_dir + img_name)\n",
    "            animal_to_imgs[animal_name].append(img)\n",
    "    return animal_to_imgs\n",
    "\n",
    "def load_info():\n",
    "    df_classes = pd.read_csv(\"classes.txt\", header=None) \n",
    "    df_predicate_matrix = pd.read_csv(\"predicate-matrix-binary.txt\", header=None)\n",
    "    df_test_classes = pd.read_csv(\"testclasses.txt\", header=None)\n",
    "    df_train_classes = pd.read_csv(\"trainclasses.txt\", header=None)\n",
    "\n",
    "    animal_to_feat = {}\n",
    "    id_to_name, name_to_id = {}, {}\n",
    "    for i, c in enumerate(df_classes[0]):\n",
    "        c_name = c.split()[1]\n",
    "        id_to_name[i] = c_name\n",
    "        name_to_id[c_name] = i\n",
    "        animal_to_feat[c_name] = np.array([int(binary) for binary in df_predicate_matrix.iloc[i, 0].split()])\n",
    "\n",
    "    train_classes, test_classes = [], []\n",
    "    for c in df_train_classes[0]: train_classes.append(c.split()[0])\n",
    "    for c in df_test_classes[0]: test_classes.append(c.split()[0])\n",
    "\n",
    "    return animal_to_feat, id_to_name, name_to_id, train_classes, test_classes\n",
    "\n",
    "def pred_class(model, img, classes):\n",
    "    s = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "    probs = np.zeros(len(classes))\n",
    "    for i, animal in enumerate(classes):\n",
    "        probs[i] = np.prod(np.abs(s - 1.0 + animal_to_feat[animal]))\n",
    "    return probs.argsort()[-1]\n",
    "\n",
    "def pred_class_ham(model, img, classes):\n",
    "    s = np.round(model.predict(np.expand_dims(img, axis=0))[0]).astype(int)\n",
    "    score = np.zeros(len(classes))\n",
    "    for i, animal in enumerate(classes):\n",
    "        score[i] = np.sum(np.abs(s - animal_to_feat[animal]))\n",
    "    return score.argsort()[0]\n",
    "\n",
    "def pred_class_sum(model, img, classes):\n",
    "    s = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "    probs = np.zeros(len(classes))\n",
    "    for i, animal in enumerate(classes):\n",
    "        probs[i] = np.sum(np.abs(s - animal_to_feat[animal]))\n",
    "    return probs.argsort()[0]\n",
    "\n",
    "def pred_class_harm(model, img, classes):\n",
    "    eps = 1e-5\n",
    "    s = model.predict(np.expand_dims(img, axis=0))[0]\n",
    "    probs = np.zeros(len(classes))\n",
    "    for i, animal in enumerate(classes):\n",
    "        pos = np.sum(np.log(eps + np.abs(s - 1.0 + animal_to_feat[animal])))\n",
    "        neg = np.sum(np.log(eps + np.abs(s - animal_to_feat[animal])))\n",
    "        probs[i] = pos - neg\n",
    "    return probs.argsort()[-1]\n",
    "\n",
    "def predictions(model, classes, animal_to_images, pred_func=pred_class):\n",
    "    y_pred, y_true = [], []\n",
    "    for i, animal in enumerate(classes):\n",
    "        for img in animal_to_images[animal]:\n",
    "            y_true.append(i)\n",
    "            y_pred.append(pred_func(model, img, classes))\n",
    "    return y_pred, y_true\n",
    "\n",
    "def pred_features(model, img):\n",
    "    return np.round(model.predict(np.expand_dims(img, axis=0))[0]).astype(int)\n",
    "\n",
    "def feature_preds(model, classes, animal_to_images):\n",
    "    y_pred, y_true = [], []\n",
    "    for animal in classes:\n",
    "        for img in animal_to_images[animal]:\n",
    "            y_true.append(animal_to_feat[animal])\n",
    "            y_pred.append(pred_features(model, img))\n",
    "    return y_pred, y_true\n",
    "\n",
    "def draw_table(scores, predicates):\n",
    "    table = tt.Texttable()\n",
    "    table.set_cols_align([\"l\", \"r\", \"l\", \"r\", \"l\", \"r\", \"l\", \"r\", \"l\", \"r\"])\n",
    "    table.set_cols_valign([\"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\"])\n",
    "    table.set_cols_width([8, 8, 8, 8, 8, 8, 8, 8, 8, 8])\n",
    "    header = [\"Feature\", \"Score\", \"Feature\", \"Score\", \"Feature\", \"Score\", \"Feature\", \"Score\", \"Feature\", \"Score\"]\n",
    "    rows = [header]\n",
    "    for i in range(0, len(scores), 5):\n",
    "        temp = []\n",
    "        for j in range(5): \n",
    "            temp.append(predicates[i + j])\n",
    "            temp.append(round(scores[i + j], 3))\n",
    "        rows.append(temp)\n",
    "    table.add_rows(rows)\n",
    "    print(table.draw())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_to_imgs = load_imgs(\"images_128x128\")\n",
    "animal_to_feat, id_to_name, name_to_id, train_classes, test_classes = load_info()\n",
    "all_classes = train_classes + test_classes\n",
    "predicate_file = pd.read_csv(\"predicates.txt\", header=None)\n",
    "predicates = []\n",
    "for line in predicate_file.iloc[:,0]: predicates.append(line.split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = load_model(\"models/final-model-90.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_test = feature_preds(model2, test_classes, animal_to_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_pred, y_test, index):\n",
    "    pred, test = y_pred[:, index], y_test[:, index]\n",
    "    d1 = [test[i] for i in range(len(pred)) if pred[i] > 0]\n",
    "    d2 = [pred[i] for i in range(len(pred)) if test[i] > 0]\n",
    "    if len(d1) == 0 or len(d2) == 0:\n",
    "        return 0.0\n",
    "    p, r = np.mean(d1), np.mean(d2)\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71024352 0.51288969 0.42555332 0.63436019 0.67524729 0.\n",
      " 0.         0.5325779  0.182562   0.14152781 0.00309119 0.78792469\n",
      " 0.59521051 0.68438146 0.61142576 0.59463851 0.59657702 0.40273738\n",
      " 0.70978821 0.4825784  0.30136986 0.3533437  0.69431078 0.38637308\n",
      " 0.         0.76865392 0.75634049 0.53310551 0.20191286 0.49283403\n",
      " 0.         0.64401246 0.         0.44006501 0.         0.\n",
      " 0.7192053  0.31672204 0.83305682 0.80792152 0.41145247 0.6578274\n",
      " 0.3826742  0.58462049 0.36587945 0.88007484 0.62433511 0.53959732\n",
      " 0.3713885  0.30109268 0.68770137 0.58438547 0.49214868 0.72081218\n",
      " 0.57351117 0.14966887 0.66424101 0.08540373 0.37279397 0.17715959\n",
      " 0.27912621 0.28590786 0.87375746 0.91334785 0.58970454 0.64712269\n",
      " 0.         0.14974705 0.35426429 0.52967359 0.41597971 0.37978142\n",
      " 0.33642931 0.71129477 0.79731458 0.7205298  0.45389722 0.\n",
      " 0.46239273 0.74425115 0.80973021 0.58803191 0.66759635 0.47160366\n",
      " 0.39799966]\n"
     ]
    }
   ],
   "source": [
    "f1_scores = np.zeros(len(predicates))\n",
    "for i in range(len(predicates)): \n",
    "    f1_scores[i] = f1_score(np.array(y_pred), np.array(y_test), i)\n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chimpanzee',\n",
       " 'giant+panda',\n",
       " 'leopard',\n",
       " 'persian+cat',\n",
       " 'pig',\n",
       " 'hippopotamus',\n",
       " 'humpback+whale',\n",
       " 'raccoon',\n",
       " 'rat',\n",
       " 'seal']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| Feature  |  Score   | Feature  |  Score   | Feature  |  Score   | Feature  |  Score   | Feature  |  Score   |\n",
      "+==========+==========+==========+==========+==========+==========+==========+==========+==========+==========+\n",
      "| black    |    0.710 | white    |    0.513 | blue     |    0.426 | brown    |    0.634 | gray     |    0.675 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| orange   |        0 | red      |        0 | yellow   |    0.533 | patches  |    0.183 | spots    |    0.142 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| stripes  |    0.003 | furry    |    0.788 | hairless |    0.595 | toughski |    0.684 | big      |    0.611 |\n",
      "|          |          |          |          |          |          | n        |          |          |          |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| small    |    0.595 | bulbous  |    0.597 | lean     |    0.403 | flippers |    0.710 | hands    |    0.483 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| hooves   |    0.301 | pads     |    0.353 | paws     |    0.694 | longleg  |    0.386 | longneck |        0 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| tail     |    0.769 | chewteet |    0.756 | meatteet |    0.533 | buckteet |    0.202 | strainte |    0.493 |\n",
      "|          |          | h        |          | h        |          | h        |          | eth      |          |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| horns    |        0 | claws    |    0.644 | tusks    |        0 | smelly   |    0.440 | flys     |        0 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| hops     |        0 | swims    |    0.719 | tunnels  |    0.317 | walks    |    0.833 | fast     |    0.808 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| slow     |    0.411 | strong   |    0.658 | weak     |    0.383 | muscle   |    0.585 | bipedal  |    0.366 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| quadrape |    0.880 | active   |    0.624 | inactive |    0.540 | nocturna |    0.371 | hibernat |    0.301 |\n",
      "| dal      |          |          |          |          |          | l        |          | e        |          |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| agility  |    0.688 | fish     |    0.584 | meat     |    0.492 | plankton |    0.721 | vegetati |    0.574 |\n",
      "|          |          |          |          |          |          |          |          | on       |          |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| insects  |    0.150 | forager  |    0.664 | grazer   |    0.085 | hunter   |    0.373 | scavenge |    0.177 |\n",
      "|          |          |          |          |          |          |          |          | r        |          |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| skimmer  |    0.279 | stalker  |    0.286 | newworld |    0.874 | oldworld |    0.913 | arctic   |    0.590 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| coastal  |    0.647 | desert   |        0 | bush     |    0.150 | plains   |    0.354 | forest   |    0.530 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| fields   |    0.416 | jungle   |    0.380 | mountain |    0.336 | ocean    |    0.711 | ground   |    0.797 |\n",
      "|          |          |          |          | s        |          |          |          |          |          |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| water    |    0.721 | tree     |    0.454 | cave     |        0 | fierce   |    0.462 | timid    |    0.744 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n",
      "| smart    |    0.810 | group    |    0.588 | solitary |    0.668 | nestspot |    0.472 | domestic |    0.398 |\n",
      "+----------+----------+----------+----------+----------+----------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "draw_table(f1_scores, predicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
